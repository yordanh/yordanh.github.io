<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Yordan Hristov</title>
    <link>https://yordanh.guthub.io/post/</link>
      <atom:link href="https://yordanh.guthub.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>https://yordanh.guthub.io/img/icon-192.png</url>
      <title>Posts</title>
      <link>https://yordanh.guthub.io/post/</link>
    </image>
    
    <item>
      <title>Disentanglement != Axis Alignment</title>
      <link>https://yordanh.guthub.io/post/0_disentanglement_not_axis_alignment/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://yordanh.guthub.io/post/0_disentanglement_not_axis_alignment/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; - The bottleneck layer of a VAE might be &lt;strong&gt;disentangled, up to a rotation&lt;/strong&gt;, which might make it look entangled upon the standard visual inspection following a linear latent axis interpolation. An additional PCA step could be all one needs.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface&lt;/h2&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;There are multiple &lt;a href=&#34;https://openreview.net/forum?id=Sy2fzU9gl&#34;&gt;metrics&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/1802.05983.pdf&#34;&gt;scores&lt;/a&gt; and &lt;a href=&#34;https://openreview.net/pdf?id=By-7dz-AZ&#34;&gt;frameworks&lt;/a&gt; in the existing literature which can be used to get a quantitative measure of &lt;em&gt;how disentangled&lt;/em&gt; a given vector space $\mathbf{z}$ is. Usually the $\mathbf{z}$ we are interested in is the bottleneck layer of a generative latent variable model - e.g. a VAE. When the model is trained on image data, often an additional visual qualitative evaluation is used as well. Each of the basis vectors spanning $\mathbf{z}$ are linearly perturbed around the origin and the reconstructed images corresponding to the series of latent perturbations are inspected as to whether they contain isolated factors of variation - abstract notions and concepts we&#39;ll call $\mathbf{c}$.&lt;/p&gt;
&lt;p&gt;Concisely, the latent space $\mathbf{z}$ of a VAE is deemed disentangled if a set of conceptually-orthogonal notions $\mathbf{c}$ are contained as a set of orthogonal vectors in $\mathbf{z}$. For example, in the image above, the notions of object size ($c_o$) and object color ($c_1$), which are conceptually-orthogonal (independent of each other), are contained in $\mathbf{z} \in \mathbb{R}^{2}$ as a pair of orthogonal vectors. Another very good and visually-supported example this recent tweet by David Pfau below:&lt;/p&gt;
&lt;div&gt;

  &lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-dnt=&#34;true&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&amp;quot;Disentangling&amp;quot; is a somewhat nebulous term in ML, but it is broadly about building models that can separate out different latent factors of variation - for instance, in vision, separating translation, rotation, and changes in lighting or color that leave objects invariant. 2/n &lt;a href=&#34;https://t.co/w9viBryx9D&#34;&gt;pic.twitter.com/w9viBryx9D&lt;/a&gt;&lt;/p&gt;&amp;mdash; David Pfau (@pfau) &lt;a href=&#34;https://twitter.com/pfau/status/1275821516219985930?ref_src=twsrc%5Etfw&#34;&gt;June 24, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;/div&gt;
&lt;p&gt;While intuitive, there&#39;s a major assumption in that form of visual evaluation which has been emphasized in &lt;a href=&#34;https://arxiv.org/abs/1901.07017&#34;&gt;this paper from Watters et. al&lt;/a&gt; - namely the assumption that the factors of variation $\mathbf{c}$ &lt;em&gt;align&lt;/em&gt; with the standart basis spanning $\mathbf{z}$. As demonstrated in the paper, and below, this is not necessarily always the case.&lt;/p&gt;
&lt;h2 id=&#34;positional-variations&#34;&gt;Positional Variations&lt;/h2&gt;
&lt;p&gt;All experiments below are reproducing the results from the &lt;a href=&#34;https://arxiv.org/abs/1901.07017&#34;&gt;Spatial Broadcast Decoder paper by Watters et. al&lt;/a&gt;. Since we want to have neat visualisations we constrain ourselves to 2D. All the data that we use is a modification of the &lt;a href=&#34;https://github.com/deepmind/dsprites-dataset&#34;&gt;Deepmind dSprites dataset&lt;/a&gt;. In the first example we have an image of a single ellipse whose X and Y positions can vary - 32 possible values for each. The X and Y position variations are our $\mathbf{c} = \{c_0, c_1\}$ conceptually orthogonal notions, contained in the image pixels.&lt;/p&gt;
&lt;p&gt;The model we used is a convolutional VAE with a spatial broadcast decoder - example implementation &lt;a href=&#34;https://github.com/yordanh/sbd-torch&#34;&gt;here&lt;/a&gt;. The question is whether we can have any 2 out of the 8 dimensions of $\mathbf{z}$ to represent the meaning of $\mathbf{c}$. Thus, after training, the all images are encoded and the two dimensions with smallest average variance predictions are identified as good candidates for encoding $\mathbf{c} = \{c_0, c_1\}$, following the rationale of the original paper.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/data_pos.png&#34; data-caption=&#34;Data with two factors of variation - $c_0 \equiv$ X-position (32 values, green line) and $c_1 \equiv$ Y-position (32 values, red line) of the ellipse.&#34;&gt;
&lt;img data-src=&#34;./img/data_pos.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Data with two factors of variation - $c_0 \equiv$ X-position (32 values, green line) and $c_1 \equiv$ Y-position (32 values, red line) of the ellipse.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;beta--1&#34;&gt;Beta = 1&lt;/h3&gt;
&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/single_beta_1.png&#34; data-caption=&#34;Example results for a disentangled but unaligned representation after training a Beta-VAE (Beta=1): (left) histogram of average predicted variances for each latent dimension; (middle) true distribution of $c_0$ and $c_1$; (right) projection of $c_0$ and $c_1$ in the subspace of $\mathbf{z}$ spanned by the two vectors with smallest predicted variance (most informative)&#34;&gt;
&lt;img data-src=&#34;./img/single_beta_1.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Example results for a &lt;strong&gt;disentangled&lt;/strong&gt; but &lt;strong&gt;unaligned&lt;/strong&gt; representation after training a Beta-VAE (Beta=1): &lt;strong&gt;(left)&lt;/strong&gt; histogram of average predicted variances for each latent dimension; &lt;strong&gt;(middle)&lt;/strong&gt; true distribution of $c_0$ and $c_1$; &lt;strong&gt;(right)&lt;/strong&gt; projection of $c_0$ and $c_1$ in the subspace of $\mathbf{z}$ spanned by the two vectors with smallest predicted variance (most informative)
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/single_beta_1_interp_basis.png&#34; data-caption=&#34;Interpolating the 2 basis vectors with smallest average predicted var - $z_0$ and $z_2$ - in the range [-2,2]; (row 1) perturbing $z_0$ corresponds to changes in both X and Y position; (row 2) perturbing $z_2$ corresponds to changes in both X and Y position;&#34;&gt;
&lt;img data-src=&#34;./img/single_beta_1_interp_basis.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the 2 basis vectors with smallest average predicted var - $z_0$ and $z_2$ - in the range [-2,2]; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing $z_0$ corresponds to changes in both X and Y position; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing $z_2$ corresponds to changes in both X and Y position;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/single_beta_1_interp_latent.png&#34; data-caption=&#34;Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; (row 1) perturbing red line corresponds to changes only in Y position; (row 2) perturbing green line corresponds to changes only in X position;&#34;&gt;
&lt;img data-src=&#34;./img/single_beta_1_interp_latent.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing red line corresponds to changes only in Y position; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing green line corresponds to changes only in X position;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/all_beta_1.png&#34; data-caption=&#34;Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.&#34;&gt;
&lt;img data-src=&#34;./img/all_beta_1.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;beta--10&#34;&gt;Beta = 10&lt;/h3&gt;
&lt;p&gt;One way to account for the observed rotation of the learned representations is by tuning the coefficient of the KL divergence and enforcing more independce between the latent vectors $\mathbf{z}$. For the keen, there are examples in the literature for more principled ways of enforcing such constraints - e.g. &lt;a href=&#34;https://arxiv.org/abs/1802.04942&#34;&gt;1&lt;/a&gt; and &lt;a href=&#34;http://proceedings.mlr.press/v89/esmaeili19a/esmaeili19a.pdf&#34;&gt;2&lt;/a&gt;. As seen below, increasing $\beta$ does lead to more consistent disentanglement and alignment - perturbing the basis vectors of $\mathbf{z}$ and the latent projections of $\mathbf{c}$ contain the same conceptual information.&lt;/p&gt;
&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/single_beta_10.png&#34; data-caption=&#34;Example results for a disentangled and aligned representation after training a Beta-VAE (Beta=10); rest is the same as above.&#34;&gt;
&lt;img data-src=&#34;./img/single_beta_10.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Example results for a &lt;strong&gt;disentangled&lt;/strong&gt; and &lt;strong&gt;aligned&lt;/strong&gt; representation after training a Beta-VAE (Beta=10); rest is the same as above.
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/single_beta_10_interp_basis.png&#34; data-caption=&#34;Interpolating the 2 basis vectors with smallest average predicted var  - $z_1$ and $z_2$ - in the range [-2,2]; (row 1) perturbing $z_2$ corresponds to changes only in Y position; (row 2) perturbing $z_1$ corresponds to changes only in X position;&#34;&gt;
&lt;img data-src=&#34;./img/single_beta_10_interp_basis.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the 2 basis vectors with smallest average predicted var  - $z_1$ and $z_2$ - in the range [-2,2]; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing $z_2$ corresponds to changes only in Y position; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing $z_1$ corresponds to changes only in X position;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/single_beta_10_interp_latent.png&#34; data-caption=&#34;Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; (row 1) perturbing red line corresponds to changes only in Y position; (row 2) perturbing green line corresponds to changes only in X position;&#34;&gt;
&lt;img data-src=&#34;./img/single_beta_10_interp_latent.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing red line corresponds to changes only in Y position; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing green line corresponds to changes only in X position;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/all_beta_10.png&#34; data-caption=&#34;Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.&#34;&gt;
&lt;img data-src=&#34;./img/all_beta_10.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It is worth noting that tuning loss coefficients like $\beta$ is very case-by-case and dataset-specific.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;color-variations&#34;&gt;Color Variations&lt;/h2&gt;
&lt;p&gt;The data used in the two experiments above contains only spatial variations for which the Spatial Broadcast Decoder (which we also use) was specifically designed. Out of interest we repeat the same two experiments, but this time with data that has no spatial variations, only color ones.&lt;/p&gt;
&lt;h3 id=&#34;data&#34;&gt;Data&lt;/h3&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/data_color.png&#34; data-caption=&#34;Data with two factors of variation - $c_0 \equiv$ Object color (32 values, green line) and $c_1 \equiv$ Background color (32 values, red line).&#34;&gt;
&lt;img data-src=&#34;./img/data_color.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Data with two factors of variation - $c_0 \equiv$ Object color (32 values, green line) and $c_1 \equiv$ Background color (32 values, red line).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;epochs--100-beta--1&#34;&gt;Epochs = 100; Beta = 1&lt;/h3&gt;
&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/color_epoch_100.png&#34; data-caption=&#34;Example results for a disentangled but unaligned representation after training a Beta-VAE (Beta=1) for 100 epochs; rest is the same as above.&#34;&gt;
&lt;img data-src=&#34;./img/color_epoch_100.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Example results for a &lt;strong&gt;disentangled&lt;/strong&gt; but &lt;strong&gt;unaligned&lt;/strong&gt; representation after training a Beta-VAE (Beta=1) for 100 epochs; rest is the same as above.
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/color_epoch_100_interp_basis.png&#34; data-caption=&#34;Interpolating the 2 basis vectors with smallest average predicted var - $z_0$ and $z_5$ - in the range [-2,2]; (row 1) perturbing $z_0$ corresponds to changes in both background color and object color; (row 2) perturbing $z_5$ corresponds to changes in both background color and object color;&#34;&gt;
&lt;img data-src=&#34;./img/color_epoch_100_interp_basis.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the 2 basis vectors with smallest average predicted var - $z_0$ and $z_5$ - in the range [-2,2]; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing $z_0$ corresponds to changes in both background color and object color; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing $z_5$ corresponds to changes in both background color and object color;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/color_epoch_100_interp_latent.png&#34; data-caption=&#34;Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; (row 1) perturbing red line corresponds to changes only in background color; (row 2) perturbing green line corresponds to changes only in object color;&#34;&gt;
&lt;img data-src=&#34;./img/color_epoch_100_interp_latent.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing red line corresponds to changes only in background color; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing green line corresponds to changes only in object color;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/all_color_epoch_100.png&#34; data-caption=&#34;Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.&#34;&gt;
&lt;img data-src=&#34;./img/all_color_epoch_100.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;epochs--300-beta--1&#34;&gt;Epochs = 300; Beta = 1&lt;/h3&gt;
&lt;p&gt;Instead of varying $\beta$, here we vary the number of training epochs. Nonetheless a similar phenomenon is illustrated - depending on how the model is optimised, the learned manifold $\mathbf{z}$ could be disentangled, even though it does not appear as such upon the standart visual inspection following a linear interpolation along the basis vectors.&lt;/p&gt;
&lt;p&gt;












&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/color_epoch_300.png&#34; data-caption=&#34;Example results for a disentangled but unaligned representation after training a Beta-VAE (Beta=1) for 300 epochs; rest is the same as above.&#34;&gt;
&lt;img data-src=&#34;./img/color_epoch_300.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Example results for a &lt;strong&gt;disentangled&lt;/strong&gt; but &lt;strong&gt;unaligned&lt;/strong&gt; representation after training a Beta-VAE (Beta=1) for 300 epochs; rest is the same as above.
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/color_epoch_300_interp_basis.png&#34; data-caption=&#34;Interpolating the 2 basis vectors with smallest average predicted var - $z_3$ and $z_4$ - in the range [-2,2]; (row 1) perturbing $z_3$ corresponds to changes only in background color; (row 2) perturbing $z_4$ corresponds to changes only in object color;&#34;&gt;
&lt;img data-src=&#34;./img/color_epoch_300_interp_basis.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the 2 basis vectors with smallest average predicted var - $z_3$ and $z_4$ - in the range [-2,2]; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing $z_3$ corresponds to changes only in background color; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing $z_4$ corresponds to changes only in object color;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/color_epoch_300_interp_latent.png&#34; data-caption=&#34;Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; (row 1) perturbing red line corresponds to changes only in background color; (row 2) perturbing green line corresponds to changes only in object color;&#34;&gt;
&lt;img data-src=&#34;./img/color_epoch_300_interp_latent.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Interpolating the latent projections of $c_0$ and $c_1$ - red and green lines above; &lt;strong&gt;(row 1)&lt;/strong&gt; perturbing red line corresponds to changes only in background color; &lt;strong&gt;(row 2)&lt;/strong&gt; perturbing green line corresponds to changes only in object color;
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./img/all_color_epoch_300.png&#34; data-caption=&#34;Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.&#34;&gt;
&lt;img data-src=&#34;./img/all_color_epoch_300.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Results from 10 different experiments. Variance histograms &amp;amp; latent projections of $\mathbf{c}$ are shown.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
